[
["15-Chapter15.html", "15 Generalized linear mixed models", " 15 Generalized linear mixed models This is a big, fat walleye. It is closely related to the yellow perch from Chapter 14, but it is a bigger, better tasting version. Likewise, GLMM is just a bigger, better tasting version of LMM. Okay, this one is definitely the last new fish data set for the book…I think. "],
["15-1-intro-15.html", "15.1 Introduction", " 15.1 Introduction In Chapter 14 we introduced the generalized linear mixed model (GLMM) through the lens of the linear mixed model (LMM). The first thing you should understand about GLMMs is that they are useful for analyzing data from a large number of distributions (basically, you can use them for any underlying error structure). They are just like GLM is to LM but with an extra “M” for our “mix” of fixed and random effects. When we use specific error structures, or make certain assumptions about the manner in which the heterogeneity of variances is structured with respect to specific factors, this model is often given specific names. For example, repeated measures ANOVA (or ANCOVA), nested ANOVA (or ANCOVA), factorial ANOVA (or ANCOVA), linear mixed models, linear mixed effects models, and generalized linear mixed effects models are all just different formulations of the GLMM with different names. It sounds confusing, but just remember this: any linear model with combinations of fixed and random effects is, at it’s core, just another GLMM! If you can convince yourself of this, you will improve your ability to understand a wide range of experimental designs and accompanying statistical models by understanding this one model type. The second thing you should understand to “get” GLMMs is what exactly is meant by a “random effect”. So far in this course we have only dealt with “fixed” effects. The fixed effect is a categorical variable that is used to explain some variation in our response of interest. When we use a fixed effect in a statistical model, we are making the assumption that the categories for this effect are “fixed”. In other words, we have assigned the the levels, or categories, based on some a priori knowledge that the levels themselves represent all possible groups that can be used to describe the data. Because of this definition, fixed effects are usually 1) things that we manipulate directly (like dosage or some other treatment), or 2) relatively simple grouping variables such as sex. By contrast, a “random effect” is an effect that we do not generally set ahead of time or manipulate, but rather one which is considered to be a sample from a population of potential categories that we cannot census or (often) control. Please note that there is not a single, widely accepted definition for either of these things in applied statistics and the definition can be context-specific. It becomes all the more confusing when we switch between maximum likelihood estimation and Bayesian inference. Don’t take it from me, though. Ask one of the world’s leading experts on the matter here. We will use examples of logistic regression and count models to investigate GLMM in this chapter and round out our discussions from Chapter 14. To do this, we will need our usual faves from the tidyverse and lme4. You know the drill: library(tidyverse) library(lme4) "],
["15-2-glmm-logistic.html", "15.2 Logistic regression", " 15.2 Logistic regression For our first example this week, we will use the choice data from a couple weeks ago that we used to demonstrate binomial logistic regression. This time, we will add in a random intercept term that will allow us to account for repeated observations within a year. This has two implications: 1) it accounts for the fact that the years in which we conducted this study are random samples from a larger, unobserved population, and 2) it accounts for the heterogeneity of variance that theoretically might occur as a result of taking multiple, and variable, numbers of measurements within a given year- thereby reducing the overall error of the model and our associated parameter estimates (in theory). ## path year hatchery length mass date flow ## 1 0 2010 1 176 57 118 345 ## 2 0 2005 1 205 101 128 1093 ## 3 0 2010 1 180 56 118 345 ## 4 0 2010 1 193 74 118 345 ## 5 0 2005 1 189 76 128 1093 ## 6 0 2010 1 180 65 118 345 15.2.1 Data Explanation These data are from a study that examined factors affecting path choice by wild and hatchery-reared endangered Atlantic salmon smolts during seaward migration in the Penobscot River, Maine. State, local, and federal fishery managers were interested in understanding what factors affected migratory routing through the lower river because there were different numbers of dams, with different estimated smolt mortality rates, on either side of a large island hydropower project in this system. If managers could understand factors influencing migratory route, they might be able to manipulate flows, stocking dates, and dam operation to improve survival of these endangered fish. Furthermore, the results of the study were used to predict the effects of dam removal, and hydropower re-allocation in the lower river on population-level consequences for these fish. Please see the &lt;08_glm_logisticRegression&gt;logistic regression module for a complete explanation of the data. 15.2.2 Data analysis We are going to use the 1/0 binary data to estimate the effects of a number of covariates of interest on the probability that an individual fish used the Stillwater Branch for migration in each year of this study using logistic regression. In order to do this, we will use the ‘logit’ link function, which can be defined as: logit &lt;- function(x) { log(x / (1 - x)) } The inverse of the logit function is: invlogit &lt;- function(x) { exp(x) / (1 + exp(x)) } Since we are not interested in the linear trend in the use of the Stillwater Branch through time, we need to convert year to factor. This is the same as if we wanted to use this as a fixed effect in the model as we did in Chapter 12.4 when we last worked with these data. choice$year &lt;- as.factor(choice$year) Next, define a set of models based on a priori combinations of explanatory variables. # First, make an empty list to hold the models mods &lt;- list() # Now, fill the list with several a priori models # Need to load the `lme4` package for the `glmer` function library(lme4) # Here is the list mods[[1]] &lt;- glmer(path ~ (1 | year) + hatchery + length + flow, family = binomial, data = choice) mods[[2]] &lt;- glmer(path ~ (1 | year) + flow, family = binomial, data = choice) mods[[3]] &lt;- glmer(path ~ (1 | year) + hatchery, family = binomial, data = choice) mods[[4]] &lt;- glmer(path ~ (1 | year) + length, family = binomial, data = choice) mods[[5]] &lt;- glmer(path ~ (1 | year) + length + hatchery, family = binomial, data = choice) mods[[6]] &lt;- glmer(path ~ (1 | year) + length + flow, family = binomial, data = choice) mods[[7]] &lt;- glmer(path ~ (1 | year) + hatchery + flow, family = binomial, data = choice) Give the models some names using the formulas for each of the models. Remember: models are stored as list objects in R, and each of those list objects (models) has names. We can reference those names using the $ notation: for (i in 1:length(mods)) { names(mods)[i] &lt;- as.character(summary(mods[[i]])$call$formula)[3] } Now, we use the AICcmodavg package to make a model selection table like we did last week: # Load the package and make the table library(AICcmodavg) modtable &lt;- aictab(cand.set = mods, modnames = names(mods)) Here, we see the best model is the one that incorporates only flow, and that the addition of length or hatchery or both doesn’t really improve the fit of our model. Therefore, we’ll go ahead and make predictions from the simplest (best) model alone. Let’s re-name that model really quick to make things easier to remember: best_mod &lt;- glmer( path ~ (1 | year) + flow, family = binomial, data = choice ) 15.2.3 Predictions Finally, we can use these models to make predictions about the relationships in our models the same way we have done previously with linear models and GLMs. # Load the merTools package library(merTools) # Simulate predictions from the relationship # stored in the model fit using our original data logit_preds &lt;- predictInterval( merMod = best_mod, level = 0.95, n.sims = 10000, stat = &quot;median&quot;, type = &quot;linear.prediction&quot; ) # Convert them to the real scale for plotting real_preds &lt;- apply(logit_preds, 2, invlogit) # Combine predictions with the original data mer_preds &lt;- data.frame(choice, real_preds) # Plot the predictions ggplot(mer_preds, aes(x = flow, y = fit, color = year, fill = year)) + geom_line(alpha = 0.10) + geom_ribbon(aes(ymin = lwr, ymax = upr, color = NULL), alpha = .3) + geom_line(aes(y = fit), lwd = 1, alpha = 0.50) + xlab(&quot;Discharge&quot;) + ylab(&quot;Probability of using Stillwater Branch&quot;) "],
["15-3-glmm-count.html", "15.3 Count models", " 15.3 Count models 15.3.1 Data explanation {glmm-count-data} We will wrap up our discussions about GLMM with a worked example of count models. For this one, we will attempt to predict counts of walleye, Sander vitreus, in spawning streams of Otsego Lake based on historical counts and climate data. We begin by reading in the data set: # Read in the walleye data eyes &lt;- read.csv(&quot;data/walleye.csv&quot;, stringsAsFactors = FALSE) Have a look at the first ten lines of the data set: head(eyes, 10) And check out the data structure: str(eyes) ## &#39;data.frame&#39;: 71 obs. of 15 variables: ## $ date : chr &quot;2009-04-01&quot; &quot;2009-04-01&quot; &quot;2009-04-01&quot; &quot;2009-04-05&quot; ... ## $ site : chr &quot;Cripple Creek&quot; &quot;Hayden Creek&quot; &quot;Shadow Brook&quot; &quot;Cripple Creek&quot; ... ## $ counts : int 1 1 1 4 61 17 50 10 1 35 ... ## $ high_f : num 48 48 48 52 52 52 NA NA 39 39 ... ## $ low_f : num 34 34 34 32 32 32 NA NA 28 28 ... ## $ high_c : num 8.89 8.89 8.89 11.11 11.11 ... ## $ low_c : num 1.11 1.11 1.11 0 0 ... ## $ mean_c : num 5 5 5 5.56 5.56 ... ## $ ddPrep : num 5 5 5 5.56 5.56 ... ## $ day : int 91 91 91 95 95 95 97 97 99 99 ... ## $ year : int 2009 2009 2009 2009 2009 2009 2009 2009 2009 2009 ... ## $ dd : num 72.4 72.4 72.4 109.3 109.3 ... ## $ dd2 : num 5240 5240 5240 11954 11954 ... ## $ daylight : num 12.7 12.7 12.7 12.9 12.9 ... ## $ daylight2: num 161 161 161 166 166 ... These data are counts of walleye that were captured in spawning tributaries of Otsego Lake during the 2009, 2013, 2017,and 2018 spawning season. These measurements are accompanied by various environmental indicators that include high and low flows, precipitation (rain and snow), high, low, mean temperatures (c) and degree days (dd), and photoperiod (daylight) on each day of the year. We will use the data to predict number of walleye we expect to see each day in the spawning tribs based on historical counts and some explanatory variables of interest. 15.3.2 Data analysis We start by estimating a model using the glmer() function. Let’s say for the sake of argument that we are simply interested in the lake-wide mean of our counts so that we know when students should, for example, be heading out to tributaries to look for walleyes in streams. For now, we will model walleye count as a function of photoperiod, with a random effect of site on the intercepts. This model assumes that there is variability in counts of spawning individuals between sites, but that the relationship between photoperiod and count is the same across all sites. In this case, we will specify a quadratic relationship between counts and dates because we expect the number of fish to increase to some point in the run before it decreases. We are not interested in the individual sites in this case, but need to account for repeated observations within spawning locations. In the lme4 package, the model might look something like this: # Load the package library(lme4) # Make the model waeMod1 &lt;- glmer(counts ~ dd + I(dd^2) + (1 | site), data = eyes, family = poisson) # Have a look-see at the results summary(waeMod1) ## Generalized linear mixed model fit by maximum likelihood (Laplace ## Approximation) [glmerMod] ## Family: poisson ( log ) ## Formula: counts ~ dd + I(dd^2) + (1 | site) ## Data: eyes ## ## AIC BIC logLik deviance df.resid ## 1440.0 1449.1 -716.0 1432.0 67 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -6.150 -2.289 -1.159 1.948 12.425 ## ## Random effects: ## Groups Name Variance Std.Dev. ## site (Intercept) 0.01095 0.1047 ## Number of obs: 71, groups: site, 3 ## ## Fixed effects: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -4.087e+00 4.066e-01 -10.05 &lt;2e-16 *** ## dd 9.275e-02 5.248e-03 17.67 &lt;2e-16 *** ## I(dd^2) -2.795e-04 1.666e-05 -16.78 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) dd ## dd -0.975 ## I(dd^2) 0.945 -0.990 ## fit warnings: ## Some predictor variables are on very different scales: consider rescaling ## convergence code: 0 ## unable to evaluate scaled gradient ## Model failed to converge: degenerate Hessian with 1 negative eigenvalues As we look through these results, we can see that we have a significant effect of degree days on spawning behavior. What’s more is that our count of spawning fish appears to increase during the year to a point before it starts to decrease. But we’ve got what appear to be some major issues related to convergence at the bottom of this output! [dun, dun, dun] Luckily, we can fix all of these issues by simply standardizing the covariate (dd) as discussed previously. This helps keep things on a unit scale for model estimation, and prevents wacky estimates like negative variances (!). You can think of this as calculating z-scores for each observation of a given variable. # Standardize the covariate eyes$sdd &lt;- as.vector(scale(eyes$dd)) # Make the model waeMod2 &lt;- glmer(counts ~ sdd + I(sdd^2) + (1 | site), data = eyes, family = poisson ) # Have a look-see at the results summary(waeMod2) ## Generalized linear mixed model fit by maximum likelihood (Laplace ## Approximation) [glmerMod] ## Family: poisson ( log ) ## Formula: counts ~ sdd + I(sdd^2) + (1 | site) ## Data: eyes ## ## AIC BIC logLik deviance df.resid ## 1440.0 1449.1 -716.0 1432.0 67 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -6.150 -2.289 -1.159 1.948 12.425 ## ## Random effects: ## Groups Name Variance Std.Dev. ## site (Intercept) 0.01095 0.1047 ## Number of obs: 71, groups: site, 3 ## ## Fixed effects: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 3.52854 0.07123 49.54 &lt;2e-16 *** ## sdd 0.45898 0.03737 12.28 &lt;2e-16 *** ## I(sdd^2) -0.67374 0.04018 -16.77 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) sdd ## sdd -0.001 ## I(sdd^2) -0.292 -0.297 15.3.3 Predictions Now, if we want, we can make a graph to show these predictions. Here, we make predictions for all years, and plot by site. # Simulate predictions from the relationship # stored in the model fit using our original data log_preds &lt;- predictInterval( merMod = waeMod2, level = 0.95, n.sims = 10000, stat = &quot;median&quot;, type = &quot;linear.prediction&quot; ) # Convert them to the real scale for plotting real_preds &lt;- apply(log_preds, 2, exp) # Combine predictions with the original data mer_preds &lt;- data.frame(eyes, real_preds) # Plot the predictions ggplot(mer_preds, aes(x = dd, y = counts, color = site, fill = site)) + geom_point(alpha = 0.10) + geom_ribbon(aes(ymin = lwr, ymax = upr, color = NULL), alpha = .3) + geom_line(aes(y = fit), lwd = 1, alpha = 0.50) + xlab(&quot;Growing degree days&quot;) + ylab(&quot;Number of walleye in stream&quot;) We can see that our mean predictions aren’t terrible, but there is quite a bit of uncertainty here, as above. In this case, it may behoove us to look at this within the context of negative binomial GLMMs, but that is a story for another day (and class!!). "],
["15-4-next-15.html", "15.4 Next steps", " 15.4 Next steps This chapter completes our investigations into linear models and their extensions. Not to fear, there is a whole wide world of statistics still out there for you to explore. In the final weeks of class, we will look at what to do when we have multiple correlated response variables (multivariate statistics), what to do when we have tons of explanatory variables but no idea how to meet assumptions of linear models we’ve discussed so far (classification and regression trees) or when we have non-linear relationships that can be common in biology. "]
]
