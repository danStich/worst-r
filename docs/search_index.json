[
["8-Chapter8.html", "8 General linear models", " 8 General linear models This is not the picture from Chapter 4. It is a new picture but it looks just like that one. That’s because they are both linear models. This one just has two intercepts! "],
["8-1-analysis-of-covariance-ancova.html", "8.1 Analysis of covariance (ANCOVA)", " 8.1 Analysis of covariance (ANCOVA) Alright, to wrap up our crazy, eye-opening introduction to linear models we are going to unleash the power of ANCOVA, or the general linear model. Hopefully the power and limitations of this approach will be readily apparent to you. If not, we will talk about them a lot more so don’t worry. ANCOVA is the way into the world of real, complex data analyses. It will serve as the foundation for the next several weeks in this course. Get to know it well, it is your friend. That said, ANCOVA is just another type of linear model (see Chapter title!), so it really doesn’t need it’s own book chapter except that it sounds scary to people. Plus, this is The Worst Stats Text eveR. We won’t spend a tone of time on the development of these models as we covered most of the important ideas in Chapter 4. Instead, we are going to jump right in with an example. We’ll need the tidyverse for this chapter, as well as the data contained in crickets.txt. Go ahead and load the tidyverse now so you don’t forget. library(tidyverse) "],
["8-2-motivation.html", "8.2 Motivation", " 8.2 Motivation So here we are: We have multiple explanatory variables that we would like to test; some are factors and some are continuous. Each of those factors has some set of statistical and biological hypotheses associated with them as related to our continuous (and still normal) response of interest. We want a nice elegant way of wrapping these all in to one analysis. How in the world are we supposed to do that? It’s easier than you might think. "],
["8-3-data.html", "8.3 Data", " 8.3 Data Read in a new data set. This data set contains pulses of two species of crickets collected under varying temperatures. # Read in the cricket data and assign it to a named object crickets &lt;- read.csv(&#39;data/crickets.txt&#39;) # Have a look head(crickets) ## Species Temp Pulse ## 1 ex 20.8 67.9 ## 2 ex 20.8 65.1 ## 3 ex 24.0 77.3 ## 4 ex 24.0 78.7 ## 5 ex 24.0 79.4 ## 6 ex 24.0 80.4 "],
["8-4-analysis.html", "8.4 Analysis", " 8.4 Analysis Here we want to investigate the effects of species and temperature on pulses of individual crickets. Our null hypotheses are that there is no difference in Pulse between Species and no change in Pulse with increasing temperature. We conduct the test at the default \\(\\alpha\\) = 0.05. We use the lm() function to fit the model, and the formula looks identical to the main-effects ANOVA and linear regression models from Chapter 4. Isn’t that handy? # Fit the model cricket_mod &lt;- lm(Pulse ~ Species + Temp, data=crickets) Install the car package. We need a function from this package for model summary because now we have a mix of categorical and continuous explanatory variables. This means we want to calculate the sums of squared errors a little differently than we did before. # Load the package after it&#39;s installed library(car) Now we create the ANVOA table for our ANCOVA model Anova(cricket_mod, type=&#39;III&#39;) ## Anova Table (Type III tests) ## ## Response: Pulse ## Sum Sq Df F value Pr(&gt;F) ## (Intercept) 25.5 1 7.9906 0.008582 ** ## Species 598.0 1 187.3994 6.272e-14 *** ## Temp 4376.1 1 1371.3541 &lt; 2.2e-16 *** ## Residuals 89.3 28 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 And we can look at the summary: summary(cricket_mod) ## ## Call: ## lm(formula = Pulse ~ Species + Temp, data = crickets) ## ## Residuals: ## Min 1Q Median 3Q Max ## -3.0128 -1.1296 -0.3912 0.9650 3.7800 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -7.21091 2.55094 -2.827 0.00858 ** ## Speciesniv -10.06529 0.73526 -13.689 6.27e-14 *** ## Temp 3.60275 0.09729 37.032 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.786 on 28 degrees of freedom ## Multiple R-squared: 0.9896, Adjusted R-squared: 0.9888 ## F-statistic: 1331 on 2 and 28 DF, p-value: &lt; 2.2e-16 We see that there are significant effects of species and temperature on the pulse of individual crickets. Everything else proceeds as in the analyses Chapter 4! We can build in complexity as needed, and we can make predictions as we did before. "],
["8-5-predictions.html", "8.5 Predictions", " 8.5 Predictions Here we will take a quick look at how to plot model predictions over our raw data to demonstrate the relationships we have discovered and to show how they compare to our observations. We should have a separate line for each group based on differences in Pulse between species, but the lines should be parallel based on how our model was formulated. Again, we will dig deep into why this is the case in Chapter 10. Note that this procedure is identical to the one we used for linear regression. That is because linear regression is just one special case of the general linear model! # Make predictions from the fitted model object using observed data predicted_pulse = predict(cricket_mod, interval = &#39;confidence&#39;) # Add these to the cricket data cricket_pred &lt;- cbind(crickets, predicted_pulse) Now, we can plot the raw data as a scatterplot and add our model estimates over the top just like we did for the swiss data in Chapter 4. # Sets up data and aesthetics ggplot(cricket_pred, aes(x = Temp, y = Pulse, color = Species, fill = Species)) + geom_point(alpha = 0.3, size = 2) + geom_line(aes(y = fit), size = 1) + geom_ribbon(aes(ymin = lwr, ymax = upr, color = NULL), alpha = .3)+ xlab(expression(paste(&#39;Temperature (&#39;, degree, &#39;C)&#39;))) "],
["8-6-next8.html", "8.6 Next steps", " 8.6 Next steps Now that you hold real power in your hands to do data analysis, we need to to have our first talk about due diligence and assumptions of the statistical models that we use. There are three fundamental assumptions that we either need to validate or address through experimental design in this class of models. Independence of observations. Normality of residuals (with mean = 0) Homogeneity of variances We will discuss what each of these means and how to assess them in Chapter 9. During remaining Chapters, we will continue to discuss methods for verifying or relaxing these assumptions to meet our needs through specific techniques. "]
]
